{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b7752f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikhi\\AppData\\Local\\Temp\\ipykernel_15784\\550025524.py:14: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv('blogs.csv', error_bad_lines=False, warn_bad_lines=True)\n",
      "C:\\Users\\nikhi\\AppData\\Local\\Temp\\ipykernel_15784\\550025524.py:14: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv('blogs.csv', error_bad_lines=False, warn_bad_lines=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1990 entries, 0 to 1989\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Data    1990 non-null   object\n",
      " 1   Labels  1990 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 31.2+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nikhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7814070351758794\n",
      "Precision: 0.8439429230459362\n",
      "Recall: 0.7814070351758794\n",
      "F1-score: 0.7801675008861262\n",
      "Sentiment                 negative  neutral  positive\n",
      "Labels                                               \n",
      "Labels                         NaN     1.00       NaN\n",
      "alt.atheism               0.350000      NaN  0.650000\n",
      "comp.graphics             0.270000      NaN  0.730000\n",
      "comp.os.ms-windows.misc   0.240000      NaN  0.760000\n",
      "comp.sys.ibm.pc.hardware  0.190000      NaN  0.810000\n",
      "comp.sys.mac.hardware     0.260000      NaN  0.740000\n",
      "comp.windows.x            0.200000     0.02  0.780000\n",
      "misc.forsale              0.210000      NaN  0.790000\n",
      "rec.autos                 0.240000      NaN  0.760000\n",
      "rec.motorcycles           0.280000      NaN  0.720000\n",
      "rec.sport.baseball        0.350000      NaN  0.650000\n",
      "rec.sport.hockey          0.400000      NaN  0.600000\n",
      "sci.crypt                 0.190000      NaN  0.810000\n",
      "sci.electronics           0.250000      NaN  0.750000\n",
      "sci.med                   0.340000      NaN  0.660000\n",
      "sci.space                 0.280000      NaN  0.720000\n",
      "soc.religion.christian    0.250000      NaN  0.750000\n",
      "talk.politics.guns        0.400000     0.01  0.590000\n",
      "talk.politics.mideast     0.290000      NaN  0.710000\n",
      "talk.politics.misc        0.260000      NaN  0.740000\n",
      "talk.religion.misc        0.191011      NaN  0.808989\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from textblob import TextBlob\n",
    "import csv\n",
    "\n",
    "# Try reading the CSV with different options\n",
    "try:\n",
    "    df = pd.read_csv('blogs.csv', error_bad_lines=False, warn_bad_lines=True)\n",
    "except pd.errors.ParserError:\n",
    "    # Read the CSV and skip rows with errors\n",
    "    cleaned_data = []\n",
    "    with open('blogs.csv', 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            try:\n",
    "                if len(row) == 2:  # Assuming there should be two columns\n",
    "                    cleaned_data.append(row)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(cleaned_data, columns=['Data', 'Labels'])\n",
    "\n",
    "# Data exploration\n",
    "df.info()\n",
    "df.isnull().sum()\n",
    "\n",
    "# Preprocess the data\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "df['Data'] = df['Data'].apply(preprocess_text)\n",
    "\n",
    "# Feature extraction\n",
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(df['Data'])\n",
    "y = df['Labels']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Naive Bayes model\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1-score: {f1}')\n",
    "\n",
    "# Sentiment analysis\n",
    "def get_sentiment(text):\n",
    "    blob = TextBlob(text)\n",
    "    if blob.sentiment.polarity > 0:\n",
    "        return 'positive'\n",
    "    elif blob.sentiment.polarity < 0:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "df['Sentiment'] = df['Data'].apply(get_sentiment)\n",
    "\n",
    "# Sentiment distribution\n",
    "sentiment_distribution = df.groupby('Labels')['Sentiment'].value_counts(normalize=True).unstack()\n",
    "print(sentiment_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ae7ade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71153cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
